{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mCIf72u4U0-J"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.ensemble import RandomForestClassifier, IsolationForest\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# ========================== STEP 1: Load & Preprocess Data ==========================\n",
        "# Load dataset\n",
        "file_path = \"/content/Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv\"  # Update this if needed\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Remove columns with high null values\n",
        "df = df.dropna(axis=1, thresh=len(df) * 0.7)\n",
        "\n",
        "# Drop non-numeric columns (if any)\n",
        "df = df.select_dtypes(include=[np.number])\n",
        "\n",
        "# Fill remaining NaN values with median\n",
        "df = df.fillna(df.median())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.columns)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jppzi2H1YYQt",
        "outputId": "bf703123-2406-45f5-e278-549491d33c1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index([' Destination Port', ' Flow Duration', ' Total Fwd Packets',\n",
            "       ' Total Backward Packets', 'Total Length of Fwd Packets',\n",
            "       ' Total Length of Bwd Packets', ' Fwd Packet Length Max',\n",
            "       ' Fwd Packet Length Min', ' Fwd Packet Length Mean',\n",
            "       ' Fwd Packet Length Std', 'Bwd Packet Length Max',\n",
            "       ' Bwd Packet Length Min', ' Bwd Packet Length Mean',\n",
            "       ' Bwd Packet Length Std', 'Flow Bytes/s', ' Flow Packets/s',\n",
            "       ' Flow IAT Mean', ' Flow IAT Std', ' Flow IAT Max', ' Flow IAT Min',\n",
            "       'Fwd IAT Total', ' Fwd IAT Mean', ' Fwd IAT Std', ' Fwd IAT Max',\n",
            "       ' Fwd IAT Min', 'Bwd IAT Total', ' Bwd IAT Mean', ' Bwd IAT Std',\n",
            "       ' Bwd IAT Max', ' Bwd IAT Min', 'Fwd PSH Flags', ' Bwd PSH Flags',\n",
            "       ' Fwd URG Flags', ' Bwd URG Flags', ' Fwd Header Length',\n",
            "       ' Bwd Header Length', 'Fwd Packets/s', ' Bwd Packets/s',\n",
            "       ' Min Packet Length', ' Max Packet Length', ' Packet Length Mean',\n",
            "       ' Packet Length Std', ' Packet Length Variance', 'FIN Flag Count',\n",
            "       ' SYN Flag Count', ' RST Flag Count', ' PSH Flag Count',\n",
            "       ' ACK Flag Count', ' URG Flag Count', ' CWE Flag Count',\n",
            "       ' ECE Flag Count', ' Down/Up Ratio', ' Average Packet Size',\n",
            "       ' Avg Fwd Segment Size', ' Avg Bwd Segment Size',\n",
            "       ' Fwd Header Length.1', 'Fwd Avg Bytes/Bulk', ' Fwd Avg Packets/Bulk',\n",
            "       ' Fwd Avg Bulk Rate', ' Bwd Avg Bytes/Bulk', ' Bwd Avg Packets/Bulk',\n",
            "       'Bwd Avg Bulk Rate', 'Subflow Fwd Packets', ' Subflow Fwd Bytes',\n",
            "       ' Subflow Bwd Packets', ' Subflow Bwd Bytes', 'Init_Win_bytes_forward',\n",
            "       ' Init_Win_bytes_backward', ' act_data_pkt_fwd',\n",
            "       ' min_seg_size_forward', 'Active Mean', ' Active Std', ' Active Max',\n",
            "       ' Active Min', 'Idle Mean', ' Idle Std', ' Idle Max', ' Idle Min'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "file_path = \"/content/Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv\"  # Update this with the actual file path\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Remove leading and trailing spaces from column names\n",
        "df.columns = df.columns.str.strip()\n",
        "\n",
        "# Step 1: Identify Label Column\n",
        "label_col = None\n",
        "for col in df.columns:\n",
        "    if 'label' in col.lower() or 'attack' in col.lower() or 'class' in col.lower():\n",
        "        label_col = col\n",
        "        break\n",
        "\n",
        "if label_col:\n",
        "    print(f\"‚úÖ Found label column: {label_col}\")\n",
        "\n",
        "    # Convert categorical labels to numerical (if needed)\n",
        "    label_encoder = LabelEncoder()\n",
        "    df[label_col] = label_encoder.fit_transform(df[label_col])\n",
        "\n",
        "    # Step 2: Data Cleaning\n",
        "    df.replace([np.inf, -np.inf], np.nan, inplace=True)  # Replace infinite values with NaN\n",
        "    df.dropna(inplace=True)  # Drop rows with NaN values\n",
        "    print(f\"üöÄ Data cleaned! Remaining samples: {len(df)}\")\n",
        "\n",
        "    # Step 3: Train-Test Split\n",
        "    X = df.drop(columns=[label_col])  # Features\n",
        "    y = df[label_col]  # Target variable\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Step 4: Train Supervised Anomaly Detection Model\n",
        "    clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "    clf.fit(X_train, y_train)\n",
        "\n",
        "    # Predictions\n",
        "    y_pred = clf.predict(X_test)\n",
        "\n",
        "    # Evaluate performance\n",
        "    print(\"üìä Supervised Learning (With Labels) Results:\")\n",
        "    print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è No attack label column found! Check dataset format.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_0VCpSwZOUb",
        "outputId": "39a16075-ee95-44f3-aa08-0283a81d0d79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Found label column: Label\n",
            "üöÄ Data cleaned! Remaining samples: 225711\n",
            "üìä Supervised Learning (With Labels) Results:\n",
            "Accuracy: 0.9999\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     19419\n",
            "           1       1.00      1.00      1.00     25724\n",
            "\n",
            "    accuracy                           1.00     45143\n",
            "   macro avg       1.00      1.00      1.00     45143\n",
            "weighted avg       1.00      1.00      1.00     45143\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4mh4Zb2dbsYq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}